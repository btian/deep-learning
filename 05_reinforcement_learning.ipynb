{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LWRreduxaC3c"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8N6rRs8CigsT",
    "outputId": "b79d42de-09e9-4c91-ec3a-29f5e44d0be4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "  from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eRNVlLYEiyaM"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "  def __init__(self, h, w, outputs):\n",
    "    super(DQN, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(3, 16, 5, 2)\n",
    "    self.bn1 = nn.BatchNorm2d(16)\n",
    "    self.conv2 = nn.Conv2d(16, 32, 5, 2)\n",
    "    self.bn2 = nn.BatchNorm2d(32)\n",
    "    self.conv3 = nn.Conv2d(32, 32, 5, 2)\n",
    "    self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "    def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "      return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "    convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "    convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "    linear_input_size = convw * convh * 32\n",
    "    self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.bn1(self.conv1(x)))\n",
    "    x = F.relu(self.bn2(self.conv2(x)))\n",
    "    x = F.relu(self.bn3(self.conv3(x)))\n",
    "    return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 762
    },
    "id": "PJUqrlb4kI1y",
    "outputId": "3a15b488-3077-468b-8e00-41944ddb5448"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tx = transforms.Compose([\n",
    "                         transforms.ToPILImage(),\n",
    "                         transforms.Resize(40, interpolation=Image.CUBIC),\n",
    "                         transforms.ToTensor()])\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "  world_width = env.x_threshold * 2\n",
    "  scale = screen_width / world_width\n",
    "  return int(env.state[0] * scale + screen_width / 2.0)  # Middle of the cart\n",
    "\n",
    "\n",
    "def get_screen():\n",
    "  screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "  _, screen_height, screen_width = screen.shape\n",
    "  screen = screen[:, int(screen_height*0.4):int(screen_height*0.8)]\n",
    "  view_width = int(screen_width * 0.6)\n",
    "  cart_location = get_cart_location(screen_width)\n",
    "  if cart_location < view_width // 2:\n",
    "    slice_range = slice(view_width)\n",
    "  elif cart_location > (screen_width - view_width // 2):\n",
    "    slice_range = slice(-view_width, None)\n",
    "  else:\n",
    "    slice_range = slice(cart_location - view_width // 2,\n",
    "                        cart_location + view_width // 2)\n",
    "  screen = screen[:, :, slice_range]\n",
    "  screen = np.ascontiguousarray(screen, np.float32) / 255\n",
    "  screen = torch.from_numpy(screen)\n",
    "  return tx(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(), interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Memory stores the transitions that the agent observes.\n",
    "# Transition maps (state, action) pairs to their (next_state, reward) result.\n",
    "# ReplayMemory is a cyclic buffer that holds the transitions observed recently.\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    \n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "        \n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nnktaH9gxcNd"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters())\n",
    "memory = ReplayMemory(10_000)\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "    \n",
    "    \n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)),\n",
    "                                  device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "    \n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "    \n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    \n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "    \n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i in range(num_episodes):\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        \n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "        memory.push(state, action, next_state, reward)\n",
    "        state = next_state\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    if i % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "           \n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "05-reinforcement_learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
